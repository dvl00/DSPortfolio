{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning & Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dvazq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dvazq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dvazq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dvazq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dvazq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datasets\n",
    "training = pd.read_csv('Training Data.csv', encoding='UTF-8')\n",
    "training = training.dropna()\n",
    "testing= pd.read_csv('Testing Data.csv')\n",
    "testing = testing.dropna()\n",
    "\n",
    "#changing binary values from float to integer\n",
    "training['label'] = training['label'].astype(int)\n",
    "testing['Spam'] = testing['Spam'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date wed NUMBER aug NUMBER NUMBER NUMBER NUMBER NUMBER chris garrigues cwg dated NUMBER NUMBERfaNUMBERd deepeddy com message id NUMBER NUMBER tmda deepeddy vircio com reproduce error repeatable like every time without fail debug log pick happening NUMBER NUMBER NUMBER pick exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER exec pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER NUMBER NUMBER ftoc pickmsgs NUMBER hit NUMBER NUMBER NUMBER marking NUMBER hits NUMBER NUMBER NUMBER tkerror syntax error expression int note run pick command hand delta pick inbox list lbrace lbrace subject ftp rbrace rbrace NUMBER NUMBER sequence mercury NUMBER hit NUMBER hit comes obviously version nmh using delta pick version pick nmh NUMBER NUMBER NUMBER compiled URL sun mar NUMBER NUMBER NUMBER NUMBER ict NUMBER relevant part mh profile delta mhparam pick seq sel list since pick command works sequence actually one explicit command line search popup one comes mh profile get created kre ps still using version code form day ago able reach cvs repository today local routing issue think exmh workers mailing list exmh workers URL URL'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['email'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning\n",
    "\n",
    "def text_cleaning(i):\n",
    "    func_list = []\n",
    "    for text in i:\n",
    "        #text = text.lower()\n",
    "        text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "        func_list.append(text)\n",
    "    return func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['email'] = text_cleaning(training['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dvazq\\Anaconda3\\envs\\DataMining\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(training['email'])):\n",
    "    \n",
    "    temp=[]\n",
    "    \n",
    "    for w in training['email'][i].split():\n",
    "        if w.lower() not in stopwords.words('english'):\n",
    "                temp.append(w)\n",
    "\n",
    "    training['email'][i] = ' '.join(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       date wed NUMBER aug NUMBER NUMBER NUMBER NUMBE...\n",
       "1       martin posted tassos papadopoulos greek sculpt...\n",
       "2       man threatens explosion moscow thursday august...\n",
       "3       klez virus die already prolific virus ever kle...\n",
       "4       adding cream spaghetti carbonara effect pasta ...\n",
       "                              ...                        \n",
       "2970    abc good morning america ranks NUMBER christma...\n",
       "2971    hyperlink hyperlink hyperlink let mortgage len...\n",
       "2972    thank shopping us gifts occasions free gift NU...\n",
       "2973    famous ebay marketing e course learn sell comp...\n",
       "2974    hello chinese traditional NUMBER NUMBER f r v ...\n",
       "Name: email, Length: 2975, dtype: object"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_bag=[]\n",
    "\n",
    "# for s in training['email']:\n",
    "#     for w in s:\n",
    "#         word_bag.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dvazq\\Anaconda3\\envs\\DataMining\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass input=TfidfVectorizer(stop_words='english', strip_accents='unicode') as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#applying countvectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(TfidfVectorizer(ngram_range=(1,1),strip_accents='unicode', lowercase=True, \n",
    "                                             analyzer='word',stop_words='english')\n",
    ")\n",
    "tfidf = vectorizer.fit(training['email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = training['email']\n",
    "y = training['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       date wed NUMBER aug NUMBER NUMBER NUMBER NUMBE...\n",
       "1       martin posted tassos papadopoulos greek sculpt...\n",
       "2       man threatens explosion moscow thursday august...\n",
       "3       klez virus die already prolific virus ever kle...\n",
       "4       adding cream spaghetti carbonara effect pasta ...\n",
       "                              ...                        \n",
       "2970    abc good morning america ranks NUMBER christma...\n",
       "2971    hyperlink hyperlink hyperlink let mortgage len...\n",
       "2972    thank shopping us gifts occasions free gift NU...\n",
       "2973    famous ebay marketing e course learn sell comp...\n",
       "2974    hello chinese traditional NUMBER NUMBER f r v ...\n",
       "Name: email, Length: 2975, dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf.fit_transform(x), y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525     0\n",
       "2875    1\n",
       "1695    0\n",
       "2823    1\n",
       "1687    0\n",
       "       ..\n",
       "1707    0\n",
       "2905    1\n",
       "210     0\n",
       "785     0\n",
       "1129    0\n",
       "Name: label, Length: 2380, dtype: int32"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(C=25)\n",
    "#build the model\n",
    "log_mod =logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94792418, 0.95287336, 0.95581352])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.95 (+/- 0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97355164, 0.97604035, 0.97730139])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.00)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00 (+/- 0.00)\n",
      "[[493   0]\n",
      " [  8  94]]\n"
     ]
    }
   ],
   "source": [
    "cross_model= cross_val_score(log_mod,X_train, y_train, cv=3, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(log_mod,X_train, y_train, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(log_mod,X_train, y_train, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(y_test,log_mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91822665, 0.91519194, 0.91204936])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.92 (+/- 0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97355164, 0.97604035, 0.97730139])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.00)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90677966, 0.82394366, 0.84732824])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.86 (+/- 0.07)\n",
      "[[479  14]\n",
      " [  6  96]]\n"
     ]
    }
   ],
   "source": [
    "cross_model= cross_val_score(clf,X_train, y_train, cv=3, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(log_mod,X_train, y_train, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(clf,X_train, y_train, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, criterion='entropy', bootstrap=False)\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50, base_estimator=rfc,\n",
    "                         learning_rate=1)\n",
    "\n",
    "RDAB = abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95057579, 0.95550832, 0.92880595])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.94 (+/- 0.02)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97355164, 0.97604035, 0.97730139])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.00)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00 (+/- 0.00)\n",
      "[[493   0]\n",
      " [ 11  91]]\n"
     ]
    }
   ],
   "source": [
    "cross_model= cross_val_score(RDAB,X_train, y_train, cv=3, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(log_mod,X_train, y_train, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(RDAB,X_train, y_train, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(y_test,RDAB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB(alpha=0.0001, fit_prior=False)\n",
    "\n",
    "abnb = AdaBoostClassifier(n_estimators=50, base_estimator=NB,\n",
    "                         learning_rate=1)\n",
    "\n",
    "ABNB = abnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96297721, 0.97289815, 0.97222611])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.97 (+/- 0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97355164, 0.97604035, 0.97730139])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.00)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9379845 , 0.92028986, 0.95348837])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.94 (+/- 0.03)\n",
      "[[490   3]\n",
      " [  1 101]]\n"
     ]
    }
   ],
   "source": [
    "cross_model= cross_val_score(ABNB,X_train, y_train, cv=3, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(log_mod,X_train, y_train, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(ABNB,X_train, y_train, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(y_test,ABNB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of accuracy all models scored 98%. However, in terms of precision, the logistic regression and AdaBoost with Random Forest as classifier scores a perfect score (100%). \n",
    "\n",
    "I also like the F1 score, which is a balance of the recall and precision score. The mode with the highest F1 score was the AdaBoost Classifier with Naive Bayes (97%). \n",
    "\n",
    "I would choose the AdaBoost Classifier with Naive Bayes as the best model for this dataset. I will now apply this classifier to my validation dataset which include my own personal emails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_testing = TfidfVectorizer(ngram_range=(1,1),strip_accents='unicode', lowercase=True, \n",
    "                         analyzer='word',stop_words='english',\n",
    "                         vocabulary=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El MiÃ©rcoles, 14 de mayo, 2014 4:07 P.M., \"Al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El , David Vazquez Lizama &lt;dvazquez_lizama@yah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delta Fligh Numer - Just call to change, they ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi President Peterson,\\nI hope you remember me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you, President.\\n\\n~ David Vazquez\\nEl J...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>senior advocate of nigeria barr williams falan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>leasing deal of the year mercedes benz eNUMBE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NUMBER lose NUMBER NUMBERlbs in NUMBER weeks f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>need health insurance in addition to featuring...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>hallo wir haben uns schon ziemlich lange nicht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Email  Spam\n",
       "0    El MiÃ©rcoles, 14 de mayo, 2014 4:07 P.M., \"Al...     0\n",
       "1    El , David Vazquez Lizama <dvazquez_lizama@yah...     0\n",
       "2    Delta Fligh Numer - Just call to change, they ...     0\n",
       "3    Hi President Peterson,\\nI hope you remember me...     0\n",
       "4    Thank you, President.\\n\\n~ David Vazquez\\nEl J...     0\n",
       "..                                                 ...   ...\n",
       "97   senior advocate of nigeria barr williams falan...     1\n",
       "98    leasing deal of the year mercedes benz eNUMBE...     1\n",
       "99   NUMBER lose NUMBER NUMBERlbs in NUMBER weeks f...     1\n",
       "100  need health insurance in addition to featuring...     1\n",
       "101  hallo wir haben uns schon ziemlich lange nicht...     1\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Cleaning\n",
    "\n",
    "def text_cleaning(i):\n",
    "    func_list = []\n",
    "    for text in i:\n",
    "        #text = text.lower()\n",
    "        text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "        func_list.append(text)\n",
    "    return func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['Email'] = text_cleaning(testing['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dvazq\\Anaconda3\\envs\\DataMining\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Removing stop words\n",
    "\n",
    "for i in range(len(testing['Email'])):\n",
    "    \n",
    "    temp=[]\n",
    "    \n",
    "    for w in testing['Email'][i].split():\n",
    "        if w.lower() not in stopwords.words('english'):\n",
    "                temp.append(w)\n",
    "\n",
    "    testing['Email'][i] = ' '.join(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix around\n",
    "\n",
    "testing = testing.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>becky adams snow edu David Vazquez</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi Julia nice see Kelly Thank taking time come...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello jm spamassassin taint orghuman growth ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi Dean actual leaving country today aware wou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Barbara Tomorrow could go morning around 10...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ya se acabo el norton que tarjeta utilizamos p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hi Becky e mail address wanted know placement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thank President David Vazquez El Jueves 22 de ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>office egnr femi daniel federal ministry works...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>David Vazquez El lun 6 23 14 David Vazquez Liz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Email  Spam\n",
       "0                   becky adams snow edu David Vazquez     0\n",
       "1    Hi Julia nice see Kelly Thank taking time come...     0\n",
       "2    hello jm spamassassin taint orghuman growth ho...     1\n",
       "3    Hi Dean actual leaving country today aware wou...     0\n",
       "4    Hi Barbara Tomorrow could go morning around 10...     0\n",
       "..                                                 ...   ...\n",
       "97   ya se acabo el norton que tarjeta utilizamos p...     0\n",
       "98   Hi Becky e mail address wanted know placement ...     0\n",
       "99   Thank President David Vazquez El Jueves 22 de ...     0\n",
       "100  office egnr femi daniel federal ministry works...     1\n",
       "101  David Vazquez El lun 6 23 14 David Vazquez Liz...     0\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = testing['Email']\n",
    "test_y = testing['Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB(alpha=0.0001, fit_prior=False)\n",
    "\n",
    "abnb = AdaBoostClassifier(n_estimators=50, base_estimator=NB,\n",
    "                         learning_rate=1)\n",
    "\n",
    "ABNB.predict(tfidf_testing.fit_transform(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.8989899 , 0.94666667])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.97 (+/- 0.08)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.91176471, 0.97058824])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.07)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.82352941, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.94 (+/- 0.17)\n",
      "[[55  6]\n",
      " [ 1 40]]\n"
     ]
    }
   ],
   "source": [
    "cross_model= cross_val_score(ABNB,tfidf_testing.fit_transform(test_x), test_y, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(ABNB,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(ABNB,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(test_y,ABNB.predict(tfidf_testing.fit_transform(test_x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "We can see that our model worked pretty well with all scores: F1, Accuracy, Precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with the other 3 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 0.82905983])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.97 (+/- 0.14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.88235294])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00 (+/- 0.00)\n",
      "[[60  1]\n",
      " [ 1 40]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "log_mod.predict(tfidf_testing.fit_transform(test_x))\n",
    "\n",
    "cross_model= cross_val_score(log_mod,tfidf_testing.fit_transform(test_x), test_y, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(log_mod,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(log_mod,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(test_y,log_mod.predict(tfidf_testing.fit_transform(test_x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95058824, 0.95194508, 0.9488491 , 0.9488491 , 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.96 (+/- 0.04)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.94117647, 0.91176471, 0.97058824])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94 (+/- 0.05)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92857143, 0.82352941, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.92 (+/- 0.14)\n",
      "[[52  9]\n",
      " [ 1 40]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "clf.predict(tfidf_testing.fit_transform(test_x))\n",
    "\n",
    "cross_model= cross_val_score(clf,tfidf_testing.fit_transform(test_x), test_y, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(clf,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(clf,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(test_y,clf.predict(tfidf_testing.fit_transform(test_x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.89903846, 1.        , 0.89010989, 0.82905983])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.92 (+/- 0.13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.94117647, 1.        , 0.94117647])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.06)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00 (+/- 0.00)\n",
      "[[61  0]\n",
      " [ 1 40]]\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost with Random Forest\n",
    "\n",
    "RDAB.predict(tfidf_testing.fit_transform(test_x))\n",
    "\n",
    "cross_model= cross_val_score(RDAB,tfidf_testing.fit_transform(test_x), test_y, scoring= \"f1_macro\")\n",
    "display(cross_model)\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "cross_model= cross_val_score(RDAB,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"accuracy\")\n",
    "display(cross_model)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "\n",
    "cross_model= cross_val_score(RDAB,tfidf_testing.fit_transform(test_x), test_y, cv=3, scoring= \"precision\")\n",
    "display(cross_model)\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (cross_model.mean(), cross_model.std() * 2))\n",
    "#0.7 or more is good\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(test_y,RDAB.predict(tfidf_testing.fit_transform(test_x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# They all work pretty well (F1 scores of 0.90+). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
